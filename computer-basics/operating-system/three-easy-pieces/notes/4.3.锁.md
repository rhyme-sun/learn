# 锁

通过对并发的介绍，我们看到了并发编程的一个最基本问题：我们希望原子式执行一系列指令，但由于单处理器上的中断（或者多个线程在多处理器上并发执行），我们做不到。

解决这个问题的一个方法时，程序员在源代码中加锁，放在临界区周围，保证临界区能够像单条原子指令一样执行。

## 锁的基本思想

这里先通过一个例子来说明锁的使用，比如假设临界区像这样，典型的更新共享变量：

```c
balance = balance + 1;
```

当然，其他临界区也是可能的，比如为链表增加一个元素，或对共享结构的复杂更新操作。

为了避免竞态条件的发生，我们给临界区增加了这样一些代码：

```c
lock_t mutex;
...
lock(&mutex);
balance = balance + 1;
unlock(&mutex);
```

其实从编码层次去看，锁就是一个变量，这个锁变量（简称锁）保存了锁在某一时刻的状态。

它要么是可用的表示没有线程持有锁，要么是被占用的表示有一个线程持有锁，正处于临界区。我们也可以保存其他的信息，比如持有锁的线程，或请求获取锁的线程队列，但这些信息会隐藏起来，锁的使用者不会发现。

lock 和 unlock 函数的语义很简单。

调用 lock 尝试获取锁，如果没有其他线程持有锁（即它是可用的），该线程会获得锁，进入临界区。这个线程有时被称为锁的持有者（owner）。如果另外一个线程对**相同的锁变量**调用 lock，因为锁被另一线程持有，该调用不会返回。这样，当持有锁的线程在临界区时，其他线程就无法进入临界区。

锁的持有者一旦调用 unlock，锁就变成可用了。这时候，如果有等待线程（卡在 lock 里），其中一个会（最终）注意到（或收到通知）锁状态的变化，获取该锁，进入临界区。

锁为程序员提供了最小程度的调度控制。我们把线程视为程序员创建的实体，但是被操作系统调度，具体方式由操作系统选择。锁让程序员获得一些控制权。通过给临界区加锁，可以保证临界区内只有一个线程活跃。锁将原本由操作系统调度的混乱状态变得更为可控。



在 POSIX 库将锁称为互斥量（mutex），使用 POSIX 库的锁，上述代码可以改造为：

```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

Pthread_mutex_lock(&lock); // wrapper; exits on failure
balance = balance + 1;
Pthread_mutex_unlock(&lock);
```

你可能还会注意到，POSIX 的 lock 和 unlock 函数会传入一个变量，因为我们可能用不同的锁来保护不同的变量。这样可以增加并发：不同于任何临界区都使用同一个大锁（**粗粒度的锁策略**），通常大家会用不同的锁保护不同的数据和结构，从而允许更多的线程进入临界区（**细粒度的锁策略**）。

## 实现锁

我们需要硬件和操作系统的帮助来实现一个可用的锁。近些年来，各种计算机体系结构的指令集都增加了一些不同的硬件原语，我们不研究这些指令是如何实现的（毕竟，这是计算机体系结构课程的主题），只研究如何使用它们来实现像锁这样的互斥原语。

### 锁指标

在实现锁之前，为了评价锁是否能工作（并工作得好），我们应该先设立一些标准。

第一是锁是否能完成它的基本任务，提供互斥（mutual exclusion），即锁是否有效，能够阻止多个线程进入临界区？

第二是公平性（fairness）。当锁可用时，是否每一个竞争线程有公平的机会抢到锁？或者说是否有竞争锁的线程会**饿死**（starve），一直无法获得锁？

最后是性能（performance），具体来说，是使用锁之后增加的时间开销。有几种场景需要考虑。一种是没有竞争的情况，即只有一个线程抢锁、释放锁的开支如何？另外一种是一个 CPU 上多个线程竞争，性能如何？最后一种是多个 CPU、多个线程竞争时的性能。通过比较不同的场景，我们能够更好地理解不同的锁技术对性能的影响。

### 控制中断

最早提供的互斥解决方案之一，就是在临界区关闭中断。这个解决方案是为单处理器系统开发的。代码如下：

```c
void lock() {
	DisableInterrupts();
}
void unlock() {
	EnableInterrupts();
}
```

假设我们运行在这样一个单处理器系统上。通过在进入临界区之前关闭中断（使用特殊的硬件指令），可以保证临界区的代码不会被中断，从而原子地执行。结束之后，我们重新打开中断（同样通过硬件指令），使得程序正常运行。

遗憾的是，这种方式有很多缺陷。

- 第一个是，这种方法要求我们允许所有调用线程执行特权操作（打开关闭中断），即操作信任这种机制不会被应用程序滥用。众所周知，如果我们必须信任任意一个程序，可能就有麻烦了。这种麻烦表现在，一个贪婪的程序可能在它开始时就调用 lock，就可以关闭中断，从而独占处理器，如果该程序在调用 lock 一直死循环，则操作系统无法通过中断重新获得控制，这时候只能通过重启系统来解决。关闭中断对应用要求太多，不太适合作为通用的同步解决方案。

- 第二，这种方案不支持多处理器。如果多个线程运行在不同的 CPU 上，每个线程都试图进入同一个临界区，关闭中断也没有作用。线程可以运行在其他处理器上，因此能够进入临界区。

- 第三，关闭中断导致中断丢失，其他需要通过中断来完成的一些操作也变得不可用，这可能会导致严重的系统问题。假如磁盘设备完成了读取请求，但 CPU 错失了这一事实，那么，操作系统如何知道去唤醒等待读取的进程？

- 最后一个不太重要的原因就是效率低。与正常指令执行相比，现代 CPU 对于关闭和打开中断的代码执行得较慢。

基于以上原因，只在很有限的情况下用关闭中断来实现互斥原语。



### 测试并设置原子指令

因为关闭中断的方法无法工作在多处理器上，所以系统设计者开始让硬件支持锁。

最简单的硬件支持是**测试并设置指令**（test-and-set instruction），也叫作**原子交换**（atomic exchange）。

为了理解 test-and-set 如何工作，我们首先实现一个不依赖它的锁，用一个变量标记锁是否被持有，代码如下所示：

```c
typedef struct lock_t { int flag; } lock_t;

void init(lock_t *mutex) {
    // 0 -> lock is available, 1 -> held
    mutex->flag = 0;
}

void lock(lock_t *mutex) {
    while (mutex->flag == 1) // TEST the flag
        ; // spin-wait (do nothing)
    mutex->flag = 1; // now SET it!
}

void unlock(lock_t *mutex) {
    mutex->flag = 0;
}
```

上述代码在获取锁时，先判断 flag 是否为 1，如果为 1，就继续循环判断是否 flag 的值是否为 1，否则继续执行，将 flag 设置为 1。这样线程会因为其他线程已经将 flag 设置为 1 了而不断地进入循环，从而达到互斥地效果。

遗憾的是，这段代码有两个问题：正确性和性能。这个正确性问题在并发编程中很常见。比如，lock 的执行序列（多线程条件下）如下：

```
call lock()
	while (flag == 1)
interrupt: switch to Thread 2
call lock()
	while (flag == 1)
	flag = 1;
interrupt: switch to Thread 1
	flag = 1; // set flag to 1 (too!)
```

从这种交替执行可以看出，通过适时的（不合时宜的）中断，我们很容易构造出两个线程都将标志设置为 1，都能进入临界区的场景。这样显然每能满足锁需要互斥这一基本要求。

性能问题表现在，在等待时长时间的自旋浪费 CPU。



因此通过一个简单的标志变量我们没有办法实现一个锁。为此我们需要操作系统的支持，幸运的是，一些系统提供了这一指令，支持基于这种概念（测试并设置）创建简单的锁。

这个更强大的指令有不同的名字：在 SPARC 上，这个指令叫 `ldstub`（load/store unsigned byte，加载/保存无符号字节）；在 `x86` 上，是 `xchg`（atomic exchange，原子交换）指令。但它们基本上在不同的平台上做同样的事，通常称为测试并设置指令（test-and-set）。我们用如下的 C 代码片段来定义测试并设置指令做了什么：

```c
int TestAndSet(int *old_ptr, int new) {
	int old = *old_ptr; // fetch old value at old_ptr
	*old_ptr = new; // store ’new’ into old_ptr
	return old; // return the old value
}
```

测试并设置指令做了下述事情，它返回 `old_ptr` 指向的旧值，同时更新为新值，当然，关键是这些代码是原子地执行。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作“测试并设置”。这一条指令完全可以实现一个简单的自旋锁（spin lock），代码如下：

```c
typedef struct lock_t { int flag; } lock_t;

void init(lock_t *mutex) {
    // 0 -> lock is available, 1 -> held
    mutex->flag = 0;
}

void lock(lock_t *mutex) {
    while (TestAndSet(&lock -> flag, 1) == 1) // TEST the flag
        ; // spin-wait (do nothing)
}

void unlock(lock_t *mutex) {
    mutex->flag = 0;
}
```

上述代码在获取锁时，判断通过 `TestAndSet(flag, 1)` 的返回值来决定下面的执行步骤，如果返回为 0，表示获取到了锁，程序继续执行，如果返回为 1，则表示其他进程占有着锁，并一直循环，直到返回的值为 0。

将测试（test 旧的锁值）和设置（set 新的值）合并为一个原子操作之后，我们保证了只有一个线程能获取锁。这就实现了一个有效的互斥原语！

从这里你应该能够看出，为什么这种锁被称为自旋锁（spin lock）。这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。



下面来看下自旋锁是否满足锁的需求。

首先通过测试并设置这一原语（操作系统支持），我们实现了互斥。

自旋锁不具备公平性，线程跳出自旋的时机完全取决于标志值改变时（flag 设置为 0）自己是否正在执行自旋代码。其无法控制让特定的线程先跳出自旋，因此可能会导致部分线程饿死。

最后对于性能，在单 CPU 的情况下，性能开销相当大。假设一个线程持有锁进入临界区时被抢占。调度器可能会运行其他每一个线程（假设有 N−1 个这种线程）。而其他线程都在竞争锁，都会在放弃 CPU 之前，自旋一个时间片，浪费 CPU 周期。

但是，在多 CPU 上，自旋锁性能不错（**如果线程数大致等于 CPU 数**）。假设线程 A 在 CPU 1，线程 B 在 CPU 2 竞争同一个锁。线 程A（CPU 1）占有锁时，线程 B 竞争锁就会自旋（在 CPU 2 上）。然而，临界区一般都很短，因此很快锁就可用，然后线程B获得锁。自旋等待其他处理器上的锁，并没有浪费很多 CPU 周期，因此效果不错。

### 比较并交换原子指令

某些系统提供了另一个硬件原语，即比较并交换指令（SPARC 系统中是 `compare-and-swap`，`x86` 系统是 `compare-and-exchange`）。下面这条指令的 C 语言伪代码：

```c
int CompareAndSwap(int *ptr, int expected, int new) {
    int original = *ptr;
    if (original == expected)
    	*ptr = new;
    return original;
}
```

比较并交换的基本思路是检测 `ptr` 指向的值是否和 `expected` 相等；如果是，更新 `ptr` 所指的值为新值。否则，什么也不做。不论哪种情况，都返回该内存地址的实际值，让调用者能够知道执行是否成功。

有了比较并交换指令，就可以实现一个锁，类似于用测试并设置那样。例如，我们只要用下面的代码替换 lock 函数：

```c
void lock(lock_t *mutex) {
    while (CompareAndSwap(&lock -> flag, 0, 1) == 1) 
        ; // spin-wait (do nothing)
}
```

利用比较并交换实现自旋锁，它的行为等价于上面分析的利用测试并设置实现的自旋锁。

### 链接的加载和条件式存储指令

 一些平台提供了实现临界区的一对指令。例如 MIPS 架构中，链接的加载和条件式存储可以用来配合使用，实现其他并发结构。下面是相关的伪代码：

```c
int LoadLinked(int *ptr) {
	return *ptr;
}

int StoreConditional(int *ptr, int value) {
	if (no update to *ptr since LoadLinked to this address) {
		*ptr = value;
		return 1; // success!
	} else {
 		return 0; // failed to update
 	}
 }
```

链接的加载指令和典型加载指令类似，都是从内存中取出值存入一个寄存器。

关键区别来自条件式存储（store-conditional）指令，只有上一次加载的地址在期间都没有更新时，才会成功，（同时更新刚才链接的加载的地址的值）。成功时，条件存储返回 1，并将 `ptr` 指的值更新为 value。失败时，返回 0，并且不会更新值。

有了链接加载和条件式存储，我们可以通过下面代码来实现锁：

```c
void lock(lock_t *lock) {
	while (1) {
		while (LoadLinked(&lock->flag) == 1)
			; // spin until it’s zero
        if (StoreConditional(&lock->flag, 1) == 1)
            return; // if set-it-to-1 was a success: all done
        // otherwise: try it all over again
	}
}

void unlock(lock_t *lock) {
    lock->flag = 0;
}
```

请注意条件式存储失败是如何发生的。一个线程调用 lock，执行了链接的加载指令，返回 0。在执行条件式存储之前，中断产生了，另一个线程进入 lock 的代码，也执行链接式加载指令，同样返回 0。现在，两个线程都执行了链接式加载指令，将要执行条件存储。重点是只有一个线程能够成功更新标志为 1，从而获得锁；第二个执行条件存储的线程会失败（因为另一个线程已经成功执行了条件更新），必须重新尝试获取锁。

### 获取并增加

最后一个硬件原语是获取并增加（fetch-and-add）指令，它能原子地返回特定地址的旧值，并且让该值自增一。获取并增加的 C 语言伪代码如下：

```c
int FetchAndAdd(int *ptr) {
    int old = *ptr;
    *ptr = old + 1;
    return old;
}
```

在这个例子中，我们会用获取并增加指令，实现一个更有趣的 ticket 锁，代码如下：

```c
typedef struct __lock_t {
    int ticket;
    int turn;
} lock_t;

void lock_init(lock_t *lock) {
    lock->ticket = 0;
    lock->turn = 0;
}

void lock(lock_t *lock) {
    int myturn = FetchAndAdd(&lock->ticket);
    while (lock->turn != myturn)
        ; // spin
}

void unlock(lock_t *lock) {
    lock->turn = lock->turn + 1;
}
```

不是用一个值，这个解决方案使用了 ticket 和 turn 变量来构建锁。基本操作也很简单：如果线程希望获取锁，首先对一个 ticket 值执行一个原子的获取并相加指令。这个值作为该线程的 `turn`（顺位）。根据全局共享的 `lock->turn` 变量，当某一个线程的（`myturn == turn`）时，则轮到这个线程进入临界区。unlock 则是增加 turn，从而下一个等待线程可以进入临界区。

和其他锁实现不同，ticket 锁实现了公平（越先调用获取并增加指令的线程会越先成功获得锁）。

## 自旋过多

基于硬件的锁简单而且有效，这也是任何好的系统或者代码的特点。

硬件支持让我们有了很大的进展：我们已经实现了有效、公平（通过 ticket 锁）的锁。但是，问题仍然存在：如果临界区的线程发生上下文切换，其他线程只能一直自旋，等待被中断的（持有锁的）进程重新运行。有什么好办法？

只有硬件支持是不够的，我们还需要操作系统支持，以解决自旋带来的问题！

### 让出锁

第一种简单友好的方法就是，在要自旋的时候，放弃 CPU，代码如下所示：

```c
void init() {
    flag = 0;
}

void lock() {
    while (TestAndSet(&flag, 1) == 1)
        yield(); // give up the CPU
}

void unlock() {
    flag = 0;
}
```

这种方法中，我们假定操作系统提供原语 `yield`，线程可以调用它主动放弃 CPU，让其他线程运行。

线程可以处于 3 种状态之一（运行、就绪和阻塞）。`yield` 系统调用能够让运行态变为就绪态，从而允许其他线程运行。因此让出线程的本质是取消了调度自己。。现在来考虑许多线程（例如 100 个）反复竞争一把锁的情况。在这种情况下，一个线程持有锁，在释放锁之前被抢占，其他 99 个线程分别调用 lock，发现锁被抢占，然后让出 CPU。假定采用某种轮转调度程序，这 99 个线程会一直处于运行—让出这种模式，直到持有锁的线程再次运行。虽然比原来的浪费 99 个时间片的自旋方案要好，但这种方法仍然成本很高，上下文切换的成本是实实在在的，因此浪费很大。

更糟的是，我们还没有考虑饿死的问题。一个线程可能一直处于让出的循环，而其他线程反复进出临界区。很显然，我们需要一种方法来解决这个问题。

### 等待队列

前面一些方法的真正问题是存在太多的偶然性。调度程序决定如何调度。如果调度不合理，线程或者一直自旋，或者一直让出 CPU。无论哪种方法，都可能造成浪费，也不能防止线程饿死。

因此，我们必须显式地施加某种控制，决定锁释放时，谁能抢到锁。为了做到这一点，我们需要操作系统的更多支持，并需要一个队列来保存等待锁的线程。

简单起见，我们利用 Solaris 提供的支持，它提供了两个调用：`park` 能够让调用线程休眠，`unpark(threadID)` 则会唤醒 `threadID` 标识的线程。

利用这两个调用，我们可以实现按照下面代码实现锁：

```c
typedef struct __lock_t {
    int flag;
    int guard;
    queue_t *q;
} lock_t;

void lock_init(lock_t *m) {
    m->flag = 0;
    m->guard = 0;
    queue_init(m->q);
}

void lock(lock_t *m) {
    while (TestAndSet(&m->guard, 1) == 1)
        ; //acquire guard lock by spinning
    if (m->flag == 0) {
        m->flag = 1; // lock is acquired
        m->guard = 0;
    } else {
        queue_add(m->q, gettid());
        m->guard = 0;
        park();
    }
}

void unlock(lock_t *m) {
    while (TestAndSet(&m->guard, 1) == 1)
        ; //acquire guard lock by spinning
    if (queue_empty(m->q))
        m->flag = 0; // let go of lock; no one wants it
    else
        unpark(queue_remove(m->q)); // hold lock
    // (for next thread!)
    m->guard = 0;
}
```

在这个例子中，我们做了两件有趣的事。首先，我们将之前的测试并设置和等待队列结合，实现了一个更高性能的锁。其次，我们通过队列来控制谁会获得锁，避免饿死。

你可能注意到，guard 基本上起到了自旋锁的作用，围绕着 flag 和队列操作。因此，这个方法并没有完全避免自旋等待。线程在获取锁或者释放锁时可能被中断，从而导致其他线程自旋等待。但是，这个自旋等待时间是很有限的（不是在有线程在执行临界区代码时自旋，而是在 `lock` 和 `unlock` 在这两个方法被调用期间自旋），因此，这种方法也许是合理的。

第二点，你可能注意到在 lock 函数中，如果线程不能获取锁（它已被持有），线程会把自己加入队列（通过调用 `gettid` 获得当前的线程 ID），将 guard 设置为 0，然后让出 CPU。

你还可能注意到了很有趣一点，当要唤醒另一个线程时，flag 并没有设置为 0。为什么呢？其实这不是错，而是必须的！线程被唤醒时，就像是从 park 调用返回，也就是说会接着 park 后的代码执行。此时线程相当于直接获得到锁了，期间 flag 没有必要设置为 0。



最后，你可能注意到解决方案中的竞争条件，比如在一个线程 A 开始调用 `park` 前，刚好发生线程切换，切换的线程 B 若刚好执行 `unpark` 方法，切换回来线程 A 执行 park 方法后进入休眠状态，但因为 `unpark` 已经发生，如果后面没有其他线程再调用 `unpark`，那么线程 A 将会一直睡眠下去。这种问题有时称为唤醒/等待竞争。

Solaris 通过增加了第三个系统调用 `separk` 来解决这一问题。通过 `setpark`，一个线程表明自己马上要 `park`，如果刚好另一个线程被调度，并且调用了`unpark`，那么后续的 `park` 调用就会直接返回，而不是一直睡眠。`lock` 调用可以做一点小修改：

```c
queue_add(m->q, gettid());
setpark(); // new code
m->guard = 0;
```

### 两阶段锁

Linux 采用的是一种古老的锁方案，多年来不断被采用，可以追溯到 20 世纪 60 年代早期的 Dahm 锁，现在也称为**两阶段锁**（two-phase lock）。两阶段锁意识到自旋可能很有用，尤其是在很快就要释放锁的场景。因此，两阶段锁的第一阶段会先自旋一段时间，希望它可以获取锁。但是，如果第一个自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用。

上文的 Linux 锁就是这种锁，不过只自旋一次；更常见的方式是在循环中自旋固定的次数，然后使用 futex 睡眠。两阶段锁是又一个杂合（hybrid）方案的例子，即结合两种好想法得到更好的想法。当然，硬件环境、线程数、其他负载等这些因素，都会影响锁的效果。事情总是这样，让单个通用目标的锁，在所有可能的场景下都很好，这是巨大的挑战。

## 总结

以上的方法展示了如今真实的锁是如何实现的：一些硬件支持（更加强大的指令）和一些操作系统支持。当然，细节有所不同，执行这些锁操作的代码通常是高度优化的。

本文是《[操作系统导论](https://weread.qq.com/web/reader/db8329d071cc7f70db8a479kc81322c012c81e728d9d180)》（英文名：《Operating Systems: three easy pieces》）第 28 章学习笔记。