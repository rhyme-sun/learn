# 数据库事务

## 事务四大特性

数据库事务是对数据库系统读写操作的更高一层抽象，代表了一个单位的数据库操作。事务将对多个数据对象的多个读写操作视为一个整体，一个操作单位，对外具有 ACID 四个特性。

- Atomicity：原子性，一个事务被视为一个不可分割的最小操作单位，一次事务中的操作要么全部成功，要么全部失败。 

- Consistency：一致性，跨表、跨行、跨事务，数据库始终保持一致状态，数据库总是从一个一致性的状态转换到另外一个一致性的状态。 

- Isolation:：隔离性，可见性，一个事务的写操作不会影响到另一个事务的**读操作**，包含 4 种隔离级别。 

- Durability：持久性，事务提交成功后，不会丢数据，如电源故障, 系统崩溃。

事务这个概念在数据库系统和用户之间提供了一层抽象，用户仅通过事务这一概念就可以享受 ACID 四个特性，而不需要自己去处理复杂的正确性需求。总的来说，要满足正确性这一需求时十分复杂的，数据库系统封装了这种复杂性，并对外提供事务这一种抽象来使得用户不用独自面都这种复杂性，用户只要选择相信和熟悉并使用这层抽象变可以做到正确性。

```
Note:
从工程学出发，如果把正确性作为最顶层的抽象或者作为最终目标，那么事务可作为正确性和正确性具体实现的中间一层抽象，它比正确性更加具体，同时也容易实现。

偏序？
// TODO ...
```

## 本地事务

### 事务原子性和持久性的实现

持久性就是将内存中的数据写入类似于磁盘这种持久化的存储器中，然而数据写入磁盘这一过程不是原子的。考虑到事务操作不止一条数据，写入多条数据必然存在部分写入成功部分还未写入的中间状态，考虑到中间状态的存在，事务提出了一致性和持久性的要求，具体如下：

- 事务处于未提交状态，部分数据写入磁盘时崩溃，要求数据库恢复时有将磁盘以写入数据进行恢复的能力，即保证一致性。
- 事务处于提交状态，数据还未写入磁盘时崩溃，要求数据库恢复时有将未写入数据重新写入磁盘的能力，即保证持久性。

**Commit Logging**

要考虑上述两种情况，保证事务的持久性和一致性，就不能在性操作内存数据一样，直接改变内存某个位置的值，而是要通过日志的形式将操作记录下来，借助于日志将数据写入磁盘这个操作（提交）分成多个阶段来执行，这种事务的实现方法叫做提交日志（Commit Logging），具体流程如下：

- 将数据操作信息包括修改什么数据，数据位于那个内存页和磁盘块中，从什么值改成什么值等以某种格式以顺序追加的方式先记录到磁盘中。

  ```
  Note:
  顺序追加是最高效的磁盘数据写入方式。
  ```

- 日志安全落盘后，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，写入磁盘。

- 数据全部写入磁盘后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化。

Commit Logging 保障数据持久性、原子性的原理并不难理解：日志中的 Commit Record 作为事务成功的标志，即使真正修改数据时崩溃了，重启后根据已经写入磁盘的日志信息恢复现场，保证了持久性；如果日志没有成功写入 Commit Record 就发生崩溃，那整个事务就是失败的，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为回滚状态，保证了原子性。

利用 Commit Logging 有一个缺陷，即对数据写入磁盘这一操作必须在 Commit Record 写入日志之后，再次之前即使磁盘 IO 十分空闲，也不会有写入操作，若并发执行事务的 Commit Record 时间点若重合了，就会容易发生同一时刻大量的写入写入。基于这一问题，提出了提前写入方案。

**提前写入（Write-Ahead Logging, WAL）**

提前写入将何时写入变动数据，按照事务提交时间点为界，分为 FORCE 和 STEAL 两种情况：

- FORCE：当事务提交后，即记录了 Commit Record，要求数据必须同时写入叫做 FORCE，不要求同时写入叫做 NO-FORCE。现实中绝大多数数据库出于磁盘 IO 性能优化的考虑都采用 NO-FORCE 策略。
- STEAL：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。

```
Note:
为什么 Commit Logging 不允许 STEAL 而 WAL 允许？
Commit Logging 这种事务的实现方式，允许 NO-FORCE，但不允许 STEAL，因为若允许在提交前就写入磁盘，若此时发生崩溃，数据库恢复时 Commit Logging 没有将已经写入磁盘的数据回滚的能力。而 WAL 允许是因为它有这样的能力，即 Undo Log，将数据写入磁盘时，必须记录和写入操作相反的日志，借助于 Undo Log，可以将已经写入磁盘的数据恢复到以前状态。
```

WAL 将日志分为 Redo Log 和 Undo Log，在奔溃恢复时会执行以下三个阶段的操作：

- **分析阶段**（Analysis）：该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合。
- **重做阶段**（Redo）：该阶段依据分析阶段中产生的待恢复的事务集合来重演历史（Repeat History），具体操作为：找出所有包含Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移除出待恢复事务集合。
- **回滚阶段**（Undo）：该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些Loser事务的目的。

### 事务隔离性实现——并发控制

#### 锁

- 读锁：也作做共享锁，多个事务可以对同一个数据添加多个读锁，**数据被加上读锁后就不能再被加上写锁**，所以其他事务不能对该数据进行写入，但仍然可以读取。对于持有读锁的事务，如果该数据只有它自己一个事务加了读锁，允许直接将其升级为写锁，然后写入数据。

- 写锁：也作做排他锁，如果数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。
- 范围锁：对于某个范围直接加排他锁，在这个范围内的数据不能被写入。

#### 事务的隔离级别

- 读未提交（READ UNCOMMITTED）：一个事务还没提交时，它做的变更就能被别的事务看到。

  脏读：读未提交意味着一个可以读取到事务为提交的数据，当事务发生回滚，上次读取到的数据就是脏数据。

  锁：不加锁。

- 读已提交（READ COMMITTED）：一个事务提交之后，它做的变更才会被其他事务看到。

  不可重复读：此种隔离级别下一个事务中前后两次读取数据可能因为另外一个事务对该数据进行修改操作而出现不一致的情况。

  锁：使用写锁，不使用读锁。

- 可重复读（REPEATABLE READ）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的，是 `InnoDB` 默认的隔离级别。

  幻读：幻读是指，在一个事务中两个完全相同的范围查询得到了不同的结果集，但对于 MySQL 来说，一个事务读取不到另一个事务对数据的修改，但却可以去更新它，并且可以查询到刚才更新的数据。

  锁：使用读写锁，不使用范围锁。

- 串行化（SERIALIZABLE）：事务串行执行。

  最严格的级别，事务串行执行，使用全部的锁，资源消耗最大。

```
Note:
对隔离级别的理解？
四种隔离级别还有另一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据过程中，受另外一个写数据的事务影响而破坏了隔离性，也就是说，隔离级别表示了同一个事务中读取数据的一致性受另一个事务写操作的影响程度。
```

#### 悲观并发控制

在悲观并发控制中，数据库程序对于数据被修改持悲观的态度，并针对不同的隔离级别使用不同的加锁方案，以此来实现数据库事务的隔离性。

- 共享锁和互斥锁：

  为了最大化数据库事务的并发能力，数据库中的每一个数据对象都有两种锁，分别是共享锁和互斥锁：

  - 共享锁：多个事务都可以获得共享锁，当一个事务持有某个数据的共享锁时，只能对这个数据进行读操作，所以共享锁也叫做读锁。

  - 互斥锁：互斥锁在多个事务之间具有排他性，当一个事务持有某个数据的互斥锁时，对这个数据可以进行读操作也可以进行写操作，互斥锁也叫做写锁。

- 两阶段锁协议（2PL）

  锁的划分可以提高数据库事务并发执行的能力，但不能限制冲突事务的执行顺序，这就有了 2PL 协议。2PL 定义了一个重要规则：**一个事务若释放了任意某一个锁，那么它再不能获取任何其它数据的锁。**这样事务就可以将操作锁的过程分为扩展和收缩两个阶段：

  1. 扩张（Growing）阶段：不断上锁，没有锁被释放。
  2. 收缩（Shrinking）阶段：锁被陆续释放，没有新的加锁。

  工程学中两阶段锁协议还有两个变种：

  1. 严格两阶段锁协议（Strict-2PL）：一个事务持有的所有互斥锁只能在提交或回滚时才能释放。
  2. 强两阶段锁协议（Rigorous-2PL）：一个事务持有的所有锁必须在提交或回滚时才能释放。

  **两阶段锁协议是一种单机数据库事务处理的并发控制方法，以保证事务发生冲突时可以串行执行，但会出现死锁问题。**

- 死锁

  // TODO ... 重新画图

  互相等待对方持有的锁。

  ![](../images/死锁示意图.png)

- 预防死锁

  - 避免死锁发生
    - wait-die，即获取锁时设置超时时间，超时了不在等待，并释放占用资源。
    - wound-wait，即先执行的事务优先获取资源，当一个事务和另一个事务抢占资源时，先执行的事务得到资源，后执行的事务释放或等待资源。
  - 死锁出现时提供解决办法
    - 检测和恢复，恢复时有能力选择最小代价的事务释放资源。

#### 乐观并发控制

- 基于时间戳的协议：时间戳协议可以保证多个事务并行情况下执行的顺序和串行情况下的执行顺序相同。具体逻辑如下：

  - 事务启动时获取数据库当前系统的时钟时间作为事务整个运行期间的时间戳。并且给数据库中的每个记录维护一个读时间戳和写时间戳，读时间戳记录该记录最近一次被读的时间，写时间戳记录记录最近一次被写的时间。
  - 事务启动后，只能读取写时间戳比事务时间戳小的记录，读取成功后立即修改记录的读时间戳为当前系统时间。
  - 事务写入数据前，只有事务时间戳大于等于记录的读时间戳和写时间戳才能正确写入，写入成功后将写时间戳更新为当前系统时间。
  - 当事务操作不满足上述两个条件时，事务回滚，由系统重新赋时并重新执行。

  - 上述时间戳可以用自增的计数器来表示。

- 基于验证机制（CAS）

  - 事务正常进行读写操作，写之前判断数据库的值和之前判断数据库里的值是否被修改，修改了后数据不能被写入，否则直接写入数据。

#### 多版本并发控制（MVCC）

MVCC，即多版本并发控制，是一个实现数据库隔离性的一种解决方案。MVCC 的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。

MVCC 的实现逻辑：

首先用一个全局自增的数值来表示事务 ID，为了方便理解，假设数据库每行都存在 CREATE_VERSION 和 DELETE_VERSION 两个字段，在一个事务中执行对数据库写操作时，执行以下逻辑：

- 新增数据时，将 CREATE_VERSION 设置为当前事务 ID，DELETE_VERSION 为空。
- 删除数据时，将 CREATE_VERSION  置空，DELETE_VERSION 设置为当前事务 ID。
- 修改数据时，先复制原来数据，执行类似于删除数据的操作，即将 CREATE_VERSION  置空，DELETE_VERSION 设置为当前事务 ID；然后将更新的数据执行类似于新增的操作，将 CREATE_VERSION 设置为当前事务 ID，DELETE_VERSION 为空。

对一个事务的写操作进行版本控制后，我们不妨来看看，这种多版本控制机制对另一个事务的读操作有什么影响？

在可重复读的隔离级别下，读取数据时，读取 CREATE_VERSION 小于等于本事务 ID 并且不为空的数据即可。

在读已提交这种隔离级别下，读取数据时，读取 CREATE_VERSION  最大的那个数据即可。

```
Note:
为什么 MVCC 无法用于读未提交和串行化？
因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。

如何避免长事务对业务的影响？
长事务有什么影响，为什么？
长事务容易造成回滚段不断增长，回滚段记录着事务中对数据每次修改的反向操作和修改后该数据的读视图，回滚段过长会占用大量存储空间，长事务还占用着锁资源，也可能拖垮整个数据库。
如何避免？
```

## 总结

### 参考链接

[[1] 周志明.The Fenix Project](https://icyfenix.cn/architect-perspective/general-architecture/api-style/rpc.html)